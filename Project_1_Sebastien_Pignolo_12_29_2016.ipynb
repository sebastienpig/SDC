{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lane Lines on a Road\n",
    "\n",
    "Sebstien Pignolo _ Udacity Self Driving Car Nanodegree -  December 2016\n",
    "\n",
    "Objectives:\n",
    "In this project we try to detect road lane lines through a series of steps forming an image processing pipeline.\n",
    "At first the pipeline is applied on images to check the validity of the algorithms, and then on videos that are simply a succession of images.\n",
    "\n",
    "Challenges encountered on videos:\n",
    "    i)  The \"solidWhiteRight.mp4\" (960x540px) has left and right lanes in white, some noise exists on the right lane\n",
    "    like a whitish trace along the right white lane, but the cv2.inRange filters this out. \n",
    "    The end of the video is less conclusive as the lines I am drawing become at times parallel with the lane\n",
    "    and don't superimpose with the road lanes. Taking the average does not allow a quick reaction if the slope changes rapidly. \n",
    "    \n",
    "    ii)  The \"solidYellowLeft.mp4\" (960x540px) adds a difficulty by adding a yellow lane and some noise\n",
    "    (some white or yellow elements along the road. The pipeline is still robust.\n",
    "    At the end of the video the left line is nto following perfectly the yellow line though.\n",
    "    The pre-defined (using measurement) range of slopes to reject non interesting lines is working most of the time.\n",
    "    \n",
    "    iii) The \"challenge.mp4\" (1280x720px) adds another level of difficulty by adding shadows,\n",
    "    more noisy white and yellow some elements along the lines, as well as a positioning the camera differently\n",
    "    (the front of the car appears). The region of interest excludes the front of the car.\n",
    "    The image color is filtered using cv2.inRange. When the shadow is too deep the lines I am drawing deviate\n",
    "    from the road lanes but they come backn quick to fit each lane lines.\n",
    "\n",
    "\n",
    "\n",
    "Pipeline: Four steps form the pipeline;\n",
    "\n",
    "Stage 1: Obtaining a gray scale image from a BGR picture\n",
    "\n",
    "    Stage 1-b: add a color filtering for the challenge videos to reject shadows on the yellow lanes\n",
    "\n",
    "Stage 2: Applying the DeCanny algorithm to detected edges\n",
    "\n",
    "    \n",
    "\n",
    "Stage 3: Applying the Hough Transform to find lines, many line segments are found of various slopes\n",
    "\n",
    "    Stage 3-a: define a region of interest before applying Hough Transform. The rest of the image is \n",
    "    Stage 3-b: Keep the lines that are in a certain range of slopes. Right and left lanes have different slopes.\n",
    "\n",
    "Stage 4: Extrapolate the line segments using Pitagore theoreme \n",
    "\n",
    "    Stage 4-b: I end up drawing one line averaging the x and y of the values of all the lines found\n",
    "    in the range of filtered slopes.\n",
    "    \n",
    "\n",
    "Repeat starting Step 1 and write the video output as a succession of images in a mp4 container.\n",
    "\n",
    "\n",
    "Remarques:\n",
    "       Remarque 1: The range of slopes for the left and right sides have been found by running the algorithms\n",
    "       with a wide range at first and then refining the range.\n",
    "       I started the algorithm with a hardcoded value for the range of slopes, and then I moved to a slighlty more\n",
    "       adpative filering taking into account the current average slope and allowing a deviation of +/-0.2\n",
    "       at both side of the current value. \n",
    "       The initial value of \"starting_slope_right\" and \"starting_slope_left\" are crucial as they decide on the\n",
    "       initial rejection of calculated slopes. The initial value should not be too far from the true value.\n",
    "       \n",
    "       \n",
    "\n",
    "       Remarque 2: This project was very interesting in the sense that it allowed me to produce the expected results\n",
    "       with a limited number of lines. I got also to see that many factors can influence the algorithm and that it is\n",
    "       challenging to produce a robust algorithm that would work in a wide range of conditions (light, noise, curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video 12_29_output_white_line.mp4\n",
      "[MoviePy] Writing video 12_29_output_white_line.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:04<00:00, 52.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: 12_29_output_white_line.mp4 \n",
      "\n",
      "CPU times: user 3.19 s, sys: 1.41 s, total: 4.6 s\n",
      "Wall time: 4.42 s\n",
      "[MoviePy] >>>> Building video 12_29_output_yellow_line.mp4\n",
      "[MoviePy] Writing video 12_29_output_yellow_line.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:18<00:00, 29.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: 12_29_output_yellow_line.mp4 \n",
      "\n",
      "CPU times: user 16.3 s, sys: 3.89 s, total: 20.2 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from __future__ import division\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "\n",
    "starting_slope_right = 0.7\n",
    "starting_slope_left = -0.7\n",
    "slope_r = []   # store all the slopes of the right lane to get the average\n",
    "slope_l = []   # store all the slopes of the left lane to get the average\n",
    "width = 960 # width of the 2 videos\n",
    "height = 540 # height of the 2 videos\n",
    "list_lines_r = []\n",
    "list_lines_l = []\n",
    "avg_list_lines = []\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    #return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines,color=[175, 4, 28], thickness=7)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "                \n",
    "        \n",
    "def draw_lines(img, lines, color, thickness):#color=[0, 255, 255], thickness=30\n",
    "    \n",
    "    global avg_list_lines\n",
    "    global starting_slope_right\n",
    "    global starting_slope_left\n",
    "    \n",
    "    for line in lines:\n",
    "        \n",
    "        for x1,y1,x2,y2 in line:\n",
    "            #print \"starting_slope right\", starting_slope_right\n",
    "            #print \"starting_slope left\", starting_slope_left\n",
    "            if ((x2 - x1)!= 0): #to avoid division by zero\n",
    "            \n",
    "                #calculate the current slope and compare to a range to reject non interesting lines\n",
    "                slope_curr = (y2 - y1) / (x2 - x1) \n",
    "                if ((slope_curr > (starting_slope_right - 0.1)) and (slope_curr < (starting_slope_right + 0.1))): #adapting the threshold to the current average\n",
    "                    \n",
    "                    slope_r.append(slope_curr)\n",
    "                    slope_avg_r = np.average(slope_r)\n",
    "                    starting_slope_right = slope_avg_r #adapting the slope to the average right slope\n",
    "                    \n",
    "                    # debugging line to fine tune the average slope\n",
    "                    #print \"average slope right lane\", slope_avg_r\n",
    "\n",
    "                    x1e, y1e = extrapolate_line(x1,y1,x2,y2, -width) \n",
    "                    x2e, y2e = extrapolate_line(x1,y1,x2,y2, width)  \n",
    "                    line = np.array([[x1e,y1e,x2e,y2e]])\n",
    "                    list_lines_r.append(line)\n",
    "                    \n",
    "                    \n",
    "                elif (slope_curr < (starting_slope_left + 0.1) and (slope_curr > (starting_slope_left - 0.1))): #>-0.71 and slope_curr <-0.67):\n",
    "                                        \n",
    "                    slope_l.append(slope_curr)\n",
    "                    slope_avg_l = np.average(slope_l)\n",
    "                    starting_slope_left = slope_avg_l #adapting the slope to the average left slope\n",
    "\n",
    "                    #print \"average slope left lane\", slope_avg_l\n",
    "\n",
    "                    x1e_l, y1e_l = extrapolate_line(x1,y1,x2,y2, -width) # bottom point\n",
    "                    x2e_l, y2e_l = extrapolate_line(x1,y1,x2,y2, width)  # top point\n",
    "                    line = np.array([[x1e_l,y1e_l,x2e_l,y2e_l]])\n",
    "                    list_lines_l.append(line)\n",
    "\n",
    "    if len(list_lines_r):\n",
    "        #selecting the mean of all the non-rejeted lines \n",
    "             \n",
    "        avg_list_lines = np.average(list_lines_r, axis=0)\n",
    "       \n",
    "        x11 = int(avg_list_lines[0][0])\n",
    "        x12 = int(avg_list_lines[0][1])\n",
    "        x21 = int(avg_list_lines[0][2])\n",
    "        x22 = int(avg_list_lines[0][3])\n",
    "        cv2.line(img, (x11,x12), (x21,x22), color, thickness)\n",
    "        \n",
    "    \n",
    "    if len(list_lines_l):\n",
    "        #selecting the mean of all the non-rejeted lines \n",
    "\n",
    "        avg_list_lines_l = np.average(list_lines_l, axis=0)\n",
    "        x11l = int(avg_list_lines_l[0][0])\n",
    "        x12l = int(avg_list_lines_l[0][1])\n",
    "        x21l = int(avg_list_lines_l[0][2])\n",
    "        x22l = int(avg_list_lines_l[0][3])\n",
    "        cv2.line(img, (x11l,x12l), (x21l,x22l), color, thickness) \n",
    "\n",
    "\n",
    "        \n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    \n",
    "  \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, alpha=0.8, beta=1., delta=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, alpha, img, beta, delta)\n",
    "\n",
    "def extrapolate_line(x1, y1, x2, y2, height):\n",
    "    \"\"\" Takes line endpoints and extroplates new endpoint\n",
    "    the region of interest takes care of the part that is to be displayed \"\"\"\n",
    "    line_lenght = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2) #triangle\n",
    "    x = x2 + ((x2 - x1) / line_lenght * height)\n",
    "    y = y2 + ((y2 - y1) / line_lenght * height)\n",
    "    return int(x), int(y)\n",
    "\n",
    "\n",
    "def detect_lanes(image):\n",
    "\n",
    "        #PIPELINE STAGE 1: Obtaining a gray scale image from a BGR picture\n",
    "    \n",
    "        # define a range of colors where to look for 200,170,40 is the yellow left lane\n",
    "        color_low = np.array([220,170,40]) #220,170,40\n",
    "        color_high = np.array([255,255,255])\n",
    "        color_mask = cv2.inRange(image, color_low, color_high)\n",
    "\n",
    "        ## WHYcopy_image = np.copy(image)\n",
    "        # getting a gray scale of the image\n",
    "        gray_image = grayscale (image)   \n",
    "        \n",
    "        \n",
    "        #PIPELINE STAGE 2: Applying the DeCanny algorithm to detected edges\n",
    "\n",
    "        # Define a kernel size for Gaussian smoothing / blurring\n",
    "        # Canny() applies a 5x5 Gaussian internally but works better with a 3x3\n",
    "        kernel_size = 3\n",
    "        blur_gray = cv2.GaussianBlur(gray_image,(kernel_size, kernel_size), 0)\n",
    "        \n",
    "        low_threshold = 50\n",
    "        high_threshold = 150\n",
    "        edges_image = canny(gray_image, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "        #PIPELINE STAGE 3: Applying the Hough Transform to find lines, many line segments are found of various slopes\n",
    "        \n",
    "        # Stage 3-a: defining a region of interest to exclude the background and get a focus\n",
    "        mask_vertices = np.array( [[[0,540],[900,540],[500,320],[460,320],[0,540]]], dtype=np.int32 ) \n",
    "        region_of_interest_gray=region_of_interest(edges_image, mask_vertices)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #Parameters for the Hough Transform, found after running several experiments\n",
    "        rho = 1\n",
    "        theta = np.pi / 180\n",
    "        threshold = 1\n",
    "        min_line_len = 20\n",
    "        max_line_gap = 20\n",
    "        line_image = np.copy(edges_image) * 0 #creating a blank to draw lines on      \n",
    "        line_image= hough_lines(region_of_interest_gray, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "\n",
    "\n",
    "        #defining a region of interest to exclude the background and give the focus on the laneLines_thirdPass.jpgs\n",
    "        region_of_interest_gray = region_of_interest(line_image, mask_vertices)\n",
    "\n",
    "        final_image = weighted_img(region_of_interest_gray, image, alpha=0.8, beta=1., delta=0.)\n",
    "\n",
    "        \n",
    "        return final_image\n",
    "\n",
    "\n",
    "def main ():\n",
    "    \n",
    "    white_output = '12_29_output_white_line.mp4'\n",
    "    clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "    white_clip = clip1.fl_image(detect_lanes) #NOTE: this function expects color images!!\n",
    "    %time white_clip.write_videofile(white_output, audio=False)\n",
    "    \n",
    "    yellow_output = '12_29_output_yellow_line.mp4'\n",
    "    clip2 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "    yellow_clip = clip2.fl_image(detect_lanes) #NOTE: this function expects color images!!\n",
    "    %time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
